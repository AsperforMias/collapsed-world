---
title: 课题组EvolvePro使用记录
published: 2025-10-26
description: '这帮做科研的人真的会写文档和代码吗（'
image: './evolvepro_diagram.png'
tags: [Evolvepro, lab]
category: 'lab'
draft: false 
lang: ''

---

## 抱怨

**我c你m的科研代码，你m写的是什么sb玩意，依赖是不全的，文档是一笔带过的，paper是只写数学/生物学术理论的，产品是不打算教人用的，就连nm的连个pip包单词拼写都nm是错的，你写你m呢写，这是什么傻x玩意，多写点是要扣你的经费么？ntm就当写写开发日记或者llm帮你写都jb写的比这好，你这sb文档最好不是什么傻鸟kimi/豆包之类的玩意写的，在学术上您值得受敬，代码可用性上ntm就是个 \*的s\*，cnm的💩文档，照着你这s*玩意能做出来就有你\*的鬼了，您才是该被linus竖中指的coding毒瘤，s\* ! **

## 前言

言归正传，这篇文章我本来想拿个llm写的文档糊一下了事的，没什么好写的，引用下某群u的话：

> 因为搞科研的就没两个会写代码的
>
> 会写代码的那两个也懒得在这种地方认真写

此言有理乎，我感觉自己正在coding上经受莫大的折磨

如果说写/看vue的文档是被开发者们拖着皮鼓，百般讨好让你看看它们最新的努力成果和对使用者的宽容

那用/看这种扫码科研项目的文档简直就是在舔写文档/写💩项目的人的皮燕子

这玩意从头到尾就不是让人用的，就差把提防写脸上了，它根本就是一个给业内评委看一眼的展示品，甚至这个展示品不能独立的从头到尾自包含的跑一次

还有学校给的服务器，“我们学校图书馆最强的服务器”，2015年出产的8代E7，还没有gpu，让我训练一个现代5090见了都倒头就拜的模型，每个时代有每个时代自己的长生不老仙丹妙药，笑死我了

60g显存，用dr3的1.5t memory硬跑那个paper原作推荐的15B model，第二天早上起来一看日志，动都不带动一下的，难绷。最后还是用自己的设备去强跑650M的，提取了一下午的plm训练用向量

##  什么是蛋白质进化？

### 用日常例子理解

想象您有一把钥匙（蛋白质），但它开锁（功能）不够顺畅。您想改进它。

**传统方法**：随机换零件，一个个试 → 太慢了

- 钥匙有 562 个零件（氨基酸）
- 每个零件可以换成 19 种其他零件
- 总共有 10,678 种可能
- 一个个试，写这项目的人试到经费耗尽也试不完

**EvolvePro 方法**：让 LLM/AI 帮您预测 → 快多了

1. 先试 20 把钥匙，记录哪个好哪个坏
2. LLM/AI 学习这 20 个的特征
3. LLM/AI 预测剩下 10,658 个哪些最有希望
4. 您只试 LLM/AI 推荐的最好的 20 个
5. 重复这个过程，越来越接近完美的钥匙

## 流程概览

```
第一阶段：准备工作（1-2 小时，计算机完成）
┌─────────────────────────────────────────────┐
│ 输入：您的蛋白质序列（562 个氨基酸）          │
│   ↓                                          │
│ 生成所有可能的单点突变体（9,482 个）          │
│   ↓                                          │
│ 用 AI 给每个突变体"拍照"（提取特征）          │
│   ↓                                          │
│ 输出：9,482 个突变体的"数字指纹"              │
└─────────────────────────────────────────────┘

第二阶段：实验 + 预测循环（2-3 个月，多轮迭代）
┌─────────────────────────────────────────────┐
│ 【第 1 轮】                                   │
│  1. 选择 10~20 个突变体（随机或理性选择）         │
│  2. 实验室测试（1-2 周）                         │
│  3. 记录数据：哪些好坏以及activity活性相对值（假设wt野型为1.0） 
│   (activity可以选用任意期望权重，包括但不限于酶活性，结合亲和度，只需要除以野型蛋白的数据得到比例即可)
│  4. LLM/AI 学习并预测剩下的 9,462 个              │
│  5.LLM/AI 推荐 Top 50 个最有希望的               │
│                                              │
│ 【第 2 轮】                                   │
│  1. 从 Top 50 里选 10~20 个测试                  │
│  2. 实验室测试（1-2 周）                      │
│  3. 累积数据：现在有 20~40 个数据点了             │
│  4. LLM/AI 重新学习，预测更准确                   │
│  5. 推荐新的 Top 50                          │
│                                              │
│ 【第 3-5 轮】                                 │
│  重复上述过程...                              │
│  数据越来越多，LLM/AI 越来越聪明                  │
│  通常 3-5 轮后找到显著改进的突变体             │
└─────────────────────────────────────────────┘

第三阶段：收获成果
┌─────────────────────────────────────────────┐
│ 获得：                                        │
│   改进的蛋白质突变体                         │
│   性能提升 50%-200%（典型）                 │
│   只用了 60-100 个实验（vs 9,482 个全试）    │
│   节省了 95% 的时间和成本                    │
└─────────────────────────────────────────────┘
```

##  详细步骤

###  阶段一：前期准备工作

#### Step 1：生成突变体序列

**做什么：**

- 从您的原始蛋白质序列出发
- 把每个位置的氨基酸都换一遍
- 生成所有可能的单点突变体

**打个比方：**

```
原始序列：MADKLN...（562 个字母）
         ↓
突变体 1：AADKLN...（第1位 M→A）
突变体 2：DADKLN...（第1位 M→D）
突变体 3：EADKLN...（第1位 M→E）
...
突变体 9482：MADKLA...（最后一位 N→A）
```

**技术细节：**

- 每个位置可以换成 19 种其他氨基酸（除了它自己）
- 562 个位置 × 19 种可能 = 10,678 种理论可能
- 实际生成 9,482 个（某些不合理的会被排除）

**输出文件：**

```
output/exp_results/your_protein/
  ├── your_protein.fasta           ← 原始序列（WT）
  └── your_protein_mutants.fasta   ← 9,482 个突变体
```

**耗时：** 几秒钟

---

#### Step 2：提取 LLM/AI 特征（嵌入向量）

**做什么：**

- 用 ESM2 语言模型给每个突变体"拍照"
- 每张"照片"是 1,280 个数字（向量）
- 这些数字代表蛋白质的特征

**为什么需要这一步？**

计算机/模型不认识 `MADKLN` 这样的字母，但认识数字。

**打个比方：**

```
人类看蛋白质：MADKLN（一串字母）
                ↓ ESM2 模型
电脑看蛋白质：[0.23, -0.15, 0.89, ..., 0.47]（1,280 个数字）
```

这 1,280 个数字包含了：

- 蛋白质的结构信息
- 氨基酸之间的相互作用
- 功能相关的特征
- ...等等

**使用的模型：**

- **ESM2-650M**（您本地勉强可用的）：6.5 亿参数，本地 CPU 运行
- **ESM2-15B**（可选）：150 亿参数，需要服务器 GPU，且至少60g**显存**

**技术细节：**

- ESM2 是 Meta（Facebook）开发的蛋白质语言模型
- 在 2.5 亿个蛋白质序列上训练
- 能"理解"蛋白质的语法和结构

**输出文件：**

```
output/plm/esm/
  └── your_protein_esm2_t33_650M_UR50D.csv
      ├── 9,483 行（9,482 突变体 + 1 WT）
      └── 1,280 列（1,280 维向量）
```

**耗时：** 3-4 小时（本地 CPU）或 1-2 小时（服务器 GPU）

---

###  阶段二：实验与预测循环

这是整个流程的核心，重复多轮，每轮包含 4 个步骤：

#### Step 3：准备实验数据

**做什么：**

创建一个 Excel 表格，记录实验结果。

**表格格式：**

| variant | activity |
| ------- | -------- |
| WT      | 1.0      |
| N58V    | 0.85     |
| Y250N   | 1.25     |
| Y268V   | 0.92     |
| L230G   | 1.15     |
| ...     | ...      |

**字段说明：**

1. **variant**（突变体名称）
   - `WT`：Wild Type = 野生型 = 原始蛋白质
   - `N58V`：第 58 位的 N（天冬酰胺）→ V（缬氨酸）
   - `Y250N`：第 250 位的 Y（酪氨酸）→ N（天冬酰胺）
   - 格式：`原氨基酸 + 位置 + 新氨基酸`

2. **activity**（活性值）
   - 实验测得的性能指标
   - 可以是任意单位（只要能比较大小）
   - **数值越大表示越好**
   - 建议以 WT 为基准（WT = 1.0）

**活性值示例：**

```
酶活性：
  WT = 100 U/mL  → 标准化为 1.0
  突变体 A = 125 U/mL → 1.25（提升 25%）
  突变体 B = 80 U/mL  → 0.80（下降 20%）

结合亲和力（Kd 越小越好）：
  WT = 100 nM    → 取倒数 → 0.01 → 标准化为 1.0
  突变体 A = 50 nM → 取倒数 → 0.02 → 2.0（提升 100%）
  突变体 B = 200 nM → 取倒数 → 0.005 → 0.5（下降 50%）
```

**第一轮要测试多少个？**

- **最少**：WT + 10 个突变体（11 个数据点）
- **推荐**：WT + 20-30 个突变体（21-31 个数据点）
- **更多更好**：数据越多，模型越准确

**如何选择突变体？**

**第一轮（没有 AI 推荐时）：**

- 方法 1：随机选择 20-30 个
- 方法 2：基于结构/功能知识选择（活性位点、关键残基等）
- 方法 3：**混合策略**（推荐）：一半随机，一半理性选择

**后续轮（有 AI 推荐时）：**

- 从 AI 推荐的 Top 50 里选择
- 可以全选 Top 20
- 或者混合：Top 10 + 随机 10（避免过拟合）

**操作步骤：**

```bash
# 1. 打开我创建的模板
libreoffice data/exp/rounds/your_protein_Round1_template.xlsx

# 2. 填写数据
#    - 第一列：突变体名称
#    - 第二列：活性值

# 3. 保存为
data/exp/rounds/your_protein_Round1.xlsx
```

**耗时：** 实验 1-2 周，填表 10 分钟

---

#### Step 4：训练模型并预测

**做什么：**

1. AI 学习您的实验数据
2. 对所有 9,482 个突变体进行预测
3. 推荐最有希望的 Top 50

**技术原理：**

使用**随机森林（Random Forest）**机器学习模型：

```
输入：
  - 9,482 个突变体的"数字指纹"（1,280 维向量）
  - 您测试的 20 个突变体的活性值

训练：
  AI 学习："哦，这些特征的突变体活性高，那些特征的活性低"

预测：
  AI 预测剩下 9,462 个突变体的活性值

输出：
  按预测活性排序，推荐 Top 50
```

**为什么用随机森林？**

- 简单有效，不容易过拟合
- 对小样本数据（20-30 个）效果好
- 不需要大量调参
- 训练速度快（几秒钟）

**操作步骤：**

```bash
# 1. 编辑快速启动脚本
nano scripts/exp/your_protein_quickstart.py

# 2. 找到 Round 1 代码块（第 93-110 行左右）
#    删除前面的 # 号（取消注释）

# Round 1
ROUND = 1
evolve.evolve(
    ROUND,
    wt_fasta_file=WT_FASTA_FILE,
    mutant_fasta_file=MUTANT_FASTA_FILE,
    rounds_data_file=ROUNDS_DATA_FILE,
    embeddings_file=EMBEDDINGS_FILE,
    output_dir=OUTPUT_DIR,
    model=MODEL,
    scaler=SCALER,
    hyperparameter_tune=HYPERPARAMETER_TUNE,
    cv=CV,
    selection=SELECTION,
    n_top=N_TOP,
)

# 3. 保存并运行
conda activate evolvepro
python scripts/exp/your_protein_quickstart.py evolve
```

**输出文件：**

```
output/exp_results/your_protein/Round1/
  ├── your_protein_Round1_predicted_variants.csv
  │   ├── 所有 9,482 个突变体的预测结果
  │   └── 按预测活性排序
  │
  ├── your_protein_Round1_predicted_variants_top50.csv
  │   └── 推荐的 Top 50（用于下一轮测试）
  │
  ├── your_protein_Round1_model_performance.png
  │   └── 模型性能图（预测 vs 实际）
  │
  └── your_protein_Round1_feature_importance.csv
      └── 哪些特征最重要
```

**查看结果：**

```bash
# 查看 Top 50 推荐
head -20 output/exp_results/your_protein/Round1/your_protein_Round1_predicted_variants_top50.csv

# 查看模型性能图
xdg-open output/exp_results/your_protein/Round1/your_protein_Round1_model_performance.png
```

**耗时：** 10-30 分钟

---

#### Step 5：第二轮实验

**做什么：**

1. 从 Top 50 推荐里选 20 个突变体
2. 实验室测试
3. 创建 Round 2 数据文件

**重要：Round 2 数据包含所有前几轮的累积数据**

```
Round 1 数据：WT + 20 个突变体（21 个数据点）
              ↓
Round 2 数据：WT + 20 个（Round 1）+ 20 个（Round 2）= 41 个数据点
              ↓
Round 3 数据：WT + 40 个（Round 1-2）+ 20 个（Round 3）= 61 个数据点
```

**Excel 格式：**

```excel
data/exp/rounds/your_protein_Round2.xlsx

variant  | activity
---------|----------
WT       | 1.0       ← 每轮都要包含
N58V     | 0.85      ← Round 1 数据
Y250N    | 1.25      ← Round 1 数据
...      | ...       ← Round 1 数据
L299F    | 1.38      ← Round 2 新数据
L313W    | 0.78      ← Round 2 新数据
...      | ...       ← Round 2 新数据
```

**操作步骤：**

```bash
# 1. 创建 Round 2 数据文件
#    - 复制 Round 1 的数据
#    - 添加 Round 2 的新数据
#    - 保存为 your_protein_Round2.xlsx

# 2. 编辑快速启动脚本
nano scripts/exp/your_protein_quickstart.py

# 3. 取消注释 Round 2 代码块

# 4. 运行
conda activate evolvepro
python scripts/exp/your_protein_quickstart.py evolve
```

**耗时：** 实验 1-2 周，计算 10-30 分钟

---

#### Step 6-N：继续迭代

重复 Step 5，直到找到满意的突变体。

**何时停止？**

- 活性不再显著提升（收敛了）
- 达到目标性能
- 预算/时间用完
- 通常 3-5 轮后收敛

**每轮的变化：**

| 轮次    | 数据量 | 模型准确度 | 发现好突变体的概率 |
| ------- | ------ | ---------- | ------------------ |
| Round 1 | 21     | 低         | 20%                |
| Round 2 | 41     | 中         | 40%                |
| Round 3 | 61     | 高         | 60%                |
| Round 4 | 81     | 很高       | 80%                |
| Round 5 | 101    | 极高       | 90%+               |

---

###  阶段三：分析与验证

#### Step 7：性能提升分析

**查看最佳突变体：**

```bash
# 查看最终推荐的突变体
head -10 output/exp_results/your_protein/Round5/your_protein_Round5_predicted_variants_top50.csv
```

**绘制进化曲线：**

```python
import pandas as pd
import matplotlib.pyplot as plt

# 读取所有轮次的数据
rounds = []
for i in range(1, 6):
    df = pd.read_excel(f'data/exp/rounds/your_protein_Round{i}.xlsx')
    df['round'] = i
    rounds.append(df)

all_data = pd.concat(rounds)

# 绘制每轮最佳活性
best_per_round = all_data.groupby('round')['activity'].max()
plt.plot(best_per_round.index, best_per_round.values, marker='o')
plt.xlabel('Round')
plt.ylabel('Best Activity')
plt.title('Evolution Progress')
plt.show()
```

**典型结果：**

```
Round 1：发现 1.5x WT 的突变体
Round 2：发现 2.0x WT 的突变体
Round 3：发现 2.5x WT 的突变体
Round 4：发现 3.0x WT 的突变体（收敛）
Round 5：仍是 3.0x WT（确认收敛）
```

---

#### Step 8：组合突变

**单点突变体不够 -> 试组合**

找到几个单独都好的突变体，组合在一起：

```
单点突变：
  Y250N：1.5x WT
  L299F：1.8x WT
  R307N：1.6x WT

组合突变：
  Y250N + L299F：2.3x WT？
  Y250N + L299F + R307N：3.5x WT？
```

**注意：** 组合效果不一定是简单叠加，需要实验验证。

##  实际案例

### 案例 1：T7 RNA 聚合酶

**目标：** 提升转录效率

**流程：**

- Round 1：测试 24 个随机突变体，发现最好的是 1.4x WT
- Round 2：测试 Top 24，发现 2.1x WT
- Round 3：测试 Top 24，发现 2.8x WT
- Round 4：测试 Top 24，发现 3.0x WT（收敛）

**最佳突变体：** Y639F, L746M, Q732R
**组合突变：** Y639F + L746M = 4.2x WT（协同效应）

**总测试：** 96 个突变体（vs 9,000+ 个全试）

---

### 案例 2：Cas12f 核酸酶

**目标：** 提升切割效率

**流程：**

- Round 1：测试 32 个（一半随机，一半活性位点附近）
- Round 2：测试 Top 32，发现 1.8x WT
- Round 3：测试 Top 32，发现 2.3x WT
- Round 4：测试 Top 32，发现 2.5x WT
- Round 5：测试 Top 32，发现 2.6x WT（收敛）

**最佳突变体：** N282D, L355F, K412R

**总测试：** 160 个突变体

---

### 案例 3：抗体亲和力优化

**目标：** 降低 Kd（提升亲和力）

**挑战：** Kd 是越小越好，需要取倒数

**数据处理：**

```
WT：Kd = 10 nM → activity = 1/10 = 0.1 → 标准化为 1.0
突变体 A：Kd = 5 nM → activity = 1/5 = 0.2 → 2.0
突变体 B：Kd = 2 nM → activity = 1/2 = 0.5 → 5.0
```

**结果：**

- 5 轮后找到 Kd = 0.5 nM 的突变体（提升 20 倍）

## 总结

上述内容一部分是llm写的文档，但我已经经过review，在650M模型下向量提取等工作流没问题

15B参数等esm2 plm没法试，也别指望自己能跑得动，建议直接找老板。Google可知其显存需求至少60g needs，在模型启动的一瞬间，显存内存就会双双过载，进程直接panic。超256g的内存勉强可以保持不发生panic，但速度非常慢，cpu硬算就更慢了，这并不是你的cpu有什么性能缺陷（当然也可能有），而是图计算和模型训练这种活就不是cpu擅长的范围，犹如让重卡车和超跑比赛车一样

一言以蔽之，科研codebase在功能上或许一个比一个神异，但在代码结构和用户友好性上那是一个比一个沟式，拒开发者于千里之外